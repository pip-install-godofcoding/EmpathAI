# AI Consultant — Empathetic Chat + Emotion Recognition

This is a self-contained prototype web app that simulates an AI mental-health consultant with:

- Empathetic chatbot trained on 200+ mock data points (yoga, breathing, consoling).
- Face emotion recognition (using face-api.js in-browser).
- Voice emotion heuristics (Web Audio API + optional SpeechRecognition for transcripts).
- Session aggregation and an end-session report (negative or normal depending on sadness signals).

Files added:
- `index.html` — Front-end UI
- `static/style.css` — Styles
- `static/client.js` — App logic (chat, emotion detection, report)
- `scripts/generate_data.js` — Generates `data/mock_data.json` with 200 entries
- `data/mock_data.json` — (generated by script)
- `server.js` — Lightweight Node static server
- `package.json` — dev dependencies and start script

Quick start (Windows PowerShell):

1. Install Node.js (if not installed).
2. Generate mock data:

```powershell
cd d:/AI_CONSULTANT
node scripts/generate_data.js
```

3. Start the server:

```powershell
node server.js
```

4. Open `http://localhost:3000` in a Chromium-based browser (Chrome/Edge) to access camera/mic.

Notes:
- Face emotion detection uses models loaded from CDN — an internet connection is required to download the weights on first use.
- SpeechRecognition (voice-to-text) works best in Chrome. If unavailable, use typed input.

If you want I can run the generator and start the server for you, or adjust thresholds and UX.

LLM integration
----------------
This project supports proxying chat requests to an external LLM (e.g., Gemini). To enable it:

1. Copy `.env.example` to `.env` and set `GEMINI_API_URL` and either `GEMINI_API_KEY` or `GEMINI_BEARER_TOKEN`.
2. Restart the server so `server.js` can pick up the environment variables.

NOTE: Do NOT commit your real `.env` into version control. Store keys securely (environment variables, secrets manager, etc.).